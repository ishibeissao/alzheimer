{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "from matplotlib import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from ipywidgets import widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(dir_path):\n",
    "    return os.listdir(dir_path)\n",
    "\n",
    "def data_analysis_histogram(dir_path, classes, verbose = 1):\n",
    "    class_dist = []\n",
    "    for c in classes:\n",
    "        class_path = os.path.join(dir_path,c)\n",
    "        class_dist.append(len(os.listdir(class_path)))\n",
    "    \n",
    "    if verbose > 0:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(\"Class distribution\")\n",
    "        plt.barh(classes, class_dist)\n",
    "        for index, value in enumerate(class_dist):\n",
    "            plt.text(value, index,str(value))\n",
    "        plt.show()\n",
    "    return class_dist\n",
    "\n",
    "def data_analysis_image_size(dir_path, classes, verbose = 1, seed = 42):\n",
    "    random.seed(seed)\n",
    "    random_class_path = os.path.join(dir_path,random.choice(classes))\n",
    "    random_img_name = random.choice(os.listdir(random_class_path))\n",
    "    random_img_path = os.path.join(random_class_path,random_img_name)\n",
    "    img = image.imread(random_img_path)\n",
    "    if verbose > 0:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(\"%s - Height: %d px x Length: %d px\" % (random_img_path,img.shape[0],img.shape[1]))\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    return (img.shape[0],img.shape[1],1)\n",
    "\n",
    "def analyse_dataset(dir_path, verbose = 1, seed = 42):\n",
    "    classes = get_classes(dir_path)\n",
    "    class_dist = data_analysis_histogram(dir_path,classes, verbose)\n",
    "    input_shape = data_analysis_image_size(dir_path,classes, verbose, seed)\n",
    "    return classes, input_shape, class_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir_path, percentage = 1, verbose = 1):\n",
    "    classes = get_classes(dir_path)\n",
    "    img_array = []\n",
    "    class_array = []\n",
    "    for c in classes:\n",
    "        class_path = os.path.join(dir_path,c)\n",
    "        imgs_name = os.listdir(class_path)\n",
    "\n",
    "        if percentage < 1:\n",
    "            imgs_name = random.sample(imgs_name, k = int(len(imgs_name)*percentage))\n",
    "\n",
    "        for i in imgs_name:\n",
    "            img_array.append(image.imread(os.path.join(class_path,i)))\n",
    "            class_array.append(c)\n",
    "    if verbose > 0:\n",
    "        print(\"Loaded %d images\" % len(img_array))\n",
    "        \n",
    "    return np.array(img_array), np.array(class_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, val_size = 0.2, verbose = 1, seed = 42):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,  y, test_size=val_size, random_state=seed)\n",
    "    if verbose > 0:\n",
    "        print(\"Train size: %d\\nValidation size: %d\" % (len(x_train), len(x_val)))\n",
    "    return x_train, x_val, y_train, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_channel_position(x, input_shape):\n",
    "    img_lin,img_col,n_channels = input_shape\n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        x = x.reshape(x.shape[0], n_channels, img_lin, img_col)\n",
    "        input_shape = (n_channels, img_lin, img_col)\n",
    "    else:\n",
    "        x = x.reshape(x.shape[0], img_lin, img_col, n_channels)\n",
    "        input_shape = (img_lin, img_col, n_channels)\n",
    "    return x, input_shape\n",
    "\n",
    "def prepare_dataset_input(x, input_shape):\n",
    "    x_scaled = x.astype('float32') / 255.0\n",
    "    return prepare_dataset_channel_position(x_scaled, input_shape)\n",
    "\n",
    "def prepare_dataset_output(y, classes):\n",
    "    class_map = {x: i for i,x in enumerate(classes)}\n",
    "    y_code = [class_map[word] for word in y]\n",
    "    y_categorical = keras.utils.to_categorical(y_code, len(classes))\n",
    "    inv_class_map = {v: k for k, v in class_map.items()}\n",
    "    return y_categorical, inv_class_map\n",
    "\n",
    "def prepare_dataset(x , y , classes, input_shape):\n",
    "    x_scaled, input_shape = prepare_dataset_input(x, input_shape)\n",
    "    y_categorical, inv_class_map = prepare_dataset_output(y, classes)\n",
    "    return x_scaled , y_categorical, inv_class_map, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_by_class(model, x, y, verbose = 1):\n",
    "    def separate_by_class(x, y):\n",
    "        n_classes = y.shape[1]\n",
    "        x_classified = [[] for _ in range(n_classes)]\n",
    "        y_classified = [[] for _ in range(n_classes)]\n",
    "        \n",
    "        for i,img in enumerate(y):\n",
    "            index = np.where(img==1)[0][0]\n",
    "            x_classified[index].append(x[i])\n",
    "            y_classified[index].append(y[i])\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            x_classified[i] = np.array(x_classified[i])\n",
    "            y_classified[i] = np.array(y_classified[i])\n",
    "            \n",
    "        return np.array(x_classified,dtype=object), np.array(y_classified,dtype=object)\n",
    "\n",
    "    x_by_class, y_by_class = separate_by_class(x,y)\n",
    "    \n",
    "    score_by_class = []\n",
    "    for i,(x,y) in enumerate(zip(x_by_class,y_by_class)):\n",
    "        score = model.evaluate(x, y, verbose = verbose)\n",
    "        score_by_class.append(score)\n",
    "\n",
    "    return score_by_class\n",
    "    \n",
    "def evaluate_model(model, x, y, inv_class_map, verbose = 1):\n",
    "    score = model.evaluate(x, y, verbose = verbose)\n",
    "    score_by_class = evaluate_model_by_class(model, x, y, verbose)\n",
    "\n",
    "    if verbose > 0:\n",
    "        print()\n",
    "        print(\"Global loss: %.4f\" % (score))\n",
    "        for i, score in enumerate(score_by_class):\n",
    "            print(\"Class %s loss: %.4f\" % (inv_class_map[i], score))\n",
    "\n",
    "    return score, score_by_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(history,verbose):\n",
    "    if verbose > 0:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.plot(history['loss'], label=\"Loss\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(model, history, dir_path = 'results'):\n",
    "    results_directory = os.path.join(dir_path)\n",
    "\n",
    "    if not os.path.exists(results_directory):\n",
    "        os.makedirs(results_directory)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    now_str = now.strftime(\"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "\n",
    "    result_directory = os.path.join(results_directory,now_str)\n",
    "\n",
    "    if not os.path.exists(result_directory):\n",
    "        os.makedirs(result_directory)\n",
    "    else:\n",
    "        raise ValueError(\"File already exists.\")\n",
    "    \n",
    "    model_path = os.path.join(result_directory,'model')\n",
    "    model.save(model_path)\n",
    "\n",
    "    evaluation_path = os.path.join(result_directory,'evaluation')\n",
    "\n",
    "    evaluation = {\n",
    "            'epochs': history.params['epochs'],\n",
    "            'history': history.history\n",
    "    }\n",
    "\n",
    "    with open(evaluation_path, 'wb') as f:\n",
    "        pickle.dump(evaluation, f)\n",
    "    \n",
    "    print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(foldername, dir_path = 'results'):\n",
    "    result_directory = os.path.join(dir_path,foldername)\n",
    "    if not os.path.exists(result_directory):\n",
    "        raise ValueError(\"Folder not found.\")\n",
    "    \n",
    "    model_path = os.path.join(result_directory,'model')\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    evaluation_path = os.path.join(result_directory,'evaluation')\n",
    "    evaluation = pickle.load(open(evaluation_path, \"rb\"))\n",
    "    \n",
    "    return model, evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn(input_shape, classes, verbose = 1):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=(1,1),  padding='same', activation='relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(len(classes), activation='softmax'))\n",
    "\n",
    "    if verbose > 0:\n",
    "        model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "\n",
    "    history = model.fit(x_train_prepared, y_train_prepared,\n",
    "                    batch_size=128,\n",
    "                    epochs=100, verbose=verbose)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, evaluation = load_result('2021-11-03-03-42-59-498819')\n",
    "history = evaluation['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "dir_path = '../Alzheimer_s Dataset/train'\n",
    "verbose_loading = 0\n",
    "verbose_training = 1\n",
    "verbose_evaluating = 1\n",
    "dataset_percentage = 1\n",
    "validation_percentage = 0.2\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading and preparing training dataset\n",
    "classes, input_shape, class_dist = analyse_dataset(dir_path, verbose_loading, seed)\n",
    "x, y = load_dataset(dir_path, dataset_percentage , verbose_loading)\n",
    "x_train, x_val, y_train, y_val = split_dataset(x, y, validation_percentage, verbose_loading, seed)\n",
    "x_train_prepared , y_train_prepared, inv_class_map, input_shape = prepare_dataset(x_train , y_train , classes, input_shape)\n",
    "x_val_prepared , y_val_prepared, _, _ = prepare_dataset(x_val , y_val , classes, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 208, 176, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 104, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 104, 88, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 52, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 52, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 146432)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 585732    \n",
      "=================================================================\n",
      "Total params: 660,228\n",
      "Trainable params: 660,228\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 1.0554\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.9316\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 0.8190\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.6106\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.4390\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.2623\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.1632\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0801\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0544\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0199\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0075\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0030\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0017\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0013\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0010\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 7.7288e-04\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 6.2947e-04\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 5.1579e-04\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.3005e-04\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.6510e-04\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.9249e-04\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.5118e-04\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.1397e-04\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.8416e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.6012e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.4344e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.2488e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.1097e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.0005e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 8.9239e-05\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 8.0003e-05\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 7.3118e-05\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 6.6523e-05\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 6.5195e-05\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 5.5690e-05\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 5.0560e-05\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 4.6469e-05\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 4.2840e-05\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.0114e-05\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.7345e-05\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.3990e-05\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.1140e-05\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.9085e-05\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.7965e-05\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.5481e-05\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 2.3599e-05\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.2091e-05\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.0636e-05\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 1.9752e-05\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.8324e-05\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.7173e-05\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 1.6425e-05\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.5187e-05\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.4454e-05\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 1.3665e-05\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 101s 3s/step - loss: 1.2886e-05\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.2260e-05\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.1746e-05\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.1145e-05\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.0451e-05\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 1.0050e-05\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 9.4472e-06\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 9.0112e-06\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 8.6413e-06\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 8.3710e-06\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 8.0399e-06\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 7.7324e-06\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 7.2248e-06\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 6.9094e-06\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 6.5218e-06\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 6.1805e-06\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 6.1347e-06\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 5.7863e-06\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 5.4504e-06\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 5.2197e-06\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 5.0949e-06\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.8289e-06\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.6714e-06\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.4986e-06\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.2960e-06\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.1097e-06\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.0780e-06\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.8604e-06\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.7889e-06\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.5595e-06\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.4558e-06\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.3352e-06\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 3.2229e-06\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.0908e-06\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 3.0132e-06\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.8785e-06\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.7810e-06\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.7072e-06\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.6095e-06\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.5989e-06\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.4677e-06\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.3811e-06\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.3160e-06\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.2333e-06\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 2.1536e-06\n",
      "INFO:tensorflow:Assets written to: results\\2021-11-03-03-42-59-498819\\model\\assets\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "# Executing\n",
    "model, history = run_cnn(input_shape, classes, verbose_training)\n",
    "save_result(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "128/128 [==============================] - 24s 191ms/step - loss: 2.1335e-06\n",
      "18/18 [==============================] - 3s 176ms/step - loss: 1.0637e-06\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 9.9341e-09\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 2.4016e-06\n",
      "46/46 [==============================] - 8s 178ms/step - loss: 2.2172e-06\n",
      "\n",
      "Global loss: 0.0000\n",
      "Class MildDemented loss: 0.0000\n",
      "Class ModerateDemented loss: 0.0000\n",
      "Class NonDemented loss: 0.0000\n",
      "Class VeryMildDemented loss: 0.0000\n",
      "\n",
      "Validation\n",
      "33/33 [==============================] - 6s 183ms/step - loss: 0.0502\n",
      "5/5 [==============================] - 1s 186ms/step - loss: 0.2566\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.1954\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0099\n",
      "11/11 [==============================] - 2s 193ms/step - loss: 0.0072\n",
      "\n",
      "Global loss: 0.0502\n",
      "Class MildDemented loss: 0.2566\n",
      "Class ModerateDemented loss: 0.1954\n",
      "Class NonDemented loss: 0.0099\n",
      "Class VeryMildDemented loss: 0.0072\n"
     ]
    }
   ],
   "source": [
    "# Evaluating CNN\n",
    "plot_loss_history(history,verbose_evaluating)\n",
    "print(\"\\nTraining\")\n",
    "train_score, train_score_by_class = evaluate_model(model, x_train_prepared, y_train_prepared, inv_class_map, verbose_evaluating)\n",
    "print(\"\\nValidation\")\n",
    "val_score, val_score_by_class = evaluate_model(model, x_val_prepared, y_val_prepared, inv_class_map, verbose_evaluating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
