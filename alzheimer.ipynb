{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "from matplotlib import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from ipywidgets import widgets\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(dir_path):\n",
    "    return os.listdir(dir_path)\n",
    "\n",
    "def data_analysis_histogram(dir_path, classes, verbose = 1):\n",
    "    class_dist = []\n",
    "    for c in classes:\n",
    "        class_path = os.path.join(dir_path,c)\n",
    "        class_dist.append(len(os.listdir(class_path)))\n",
    "    \n",
    "    if verbose > 0:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(\"Class distribution\")\n",
    "        plt.barh(classes, class_dist)\n",
    "        for index, value in enumerate(class_dist):\n",
    "            plt.text(value, index,str(value))\n",
    "        plt.show()\n",
    "    return class_dist\n",
    "\n",
    "def data_analysis_image_size(dir_path, classes, verbose = 1, seed = 42):\n",
    "    random.seed(seed)\n",
    "    random_class_path = os.path.join(dir_path,random.choice(classes))\n",
    "    random_img_name = random.choice(os.listdir(random_class_path))\n",
    "    random_img_path = os.path.join(random_class_path,random_img_name)\n",
    "    img = image.imread(random_img_path)\n",
    "    if verbose > 0:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(\"%s - Height: %d px x Length: %d px\" % (random_img_path,img.shape[0],img.shape[1]))\n",
    "        plt.imshow(img)\n",
    "    \n",
    "    return (img.shape[0],img.shape[1],1)\n",
    "\n",
    "def analyse_dataset(dir_path, verbose = 1, seed = 42):\n",
    "    classes = get_classes(dir_path)\n",
    "    class_dist = data_analysis_histogram(dir_path,classes, verbose)\n",
    "    input_shape = data_analysis_image_size(dir_path,classes, verbose, seed)\n",
    "    return classes, input_shape, class_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir_path, percentage = 1, verbose = 1):\n",
    "    classes = get_classes(dir_path)\n",
    "    img_array = []\n",
    "    class_array = []\n",
    "    for c in classes:\n",
    "        class_path = os.path.join(dir_path,c)\n",
    "        imgs_name = os.listdir(class_path)\n",
    "\n",
    "        if percentage < 1:\n",
    "            imgs_name = random.sample(imgs_name, k = int(len(imgs_name)*percentage))\n",
    "\n",
    "        for i in imgs_name:\n",
    "            img_array.append(image.imread(os.path.join(class_path,i)))\n",
    "            class_array.append(c)\n",
    "    if verbose > 0:\n",
    "        print(\"Loaded %d images\" % len(img_array))\n",
    "        \n",
    "    return np.array(img_array), np.array(class_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y, val_size = 0.2, verbose = 1, seed = 42):\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,  y, test_size=val_size, random_state=seed)\n",
    "    if verbose > 0:\n",
    "        print(\"Train size: %d\\nValidation size: %d\" % (len(x_train), len(x_val)))\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_channel_position(x, input_shape):\n",
    "    img_lin,img_col,n_channels = input_shape\n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        x = x.reshape(x.shape[0], n_channels, img_lin, img_col)\n",
    "        input_shape = (n_channels, img_lin, img_col)\n",
    "    else:\n",
    "        x = x.reshape(x.shape[0], img_lin, img_col, n_channels)\n",
    "        input_shape = (img_lin, img_col, n_channels)\n",
    "    return x, input_shape\n",
    "\n",
    "def prepare_dataset_input(x, input_shape):\n",
    "    x_scaled = x.astype('float32') / 255.0\n",
    "    return prepare_dataset_channel_position(x_scaled, input_shape)\n",
    "\n",
    "def prepare_dataset_output(y, classes):\n",
    "    class_map = {x: i for i,x in enumerate(classes)}\n",
    "    y_code = [class_map[word] for word in y]\n",
    "    y_categorical = keras.utils.to_categorical(y_code, len(classes))\n",
    "    inv_class_map = {v: k for k, v in class_map.items()}\n",
    "    return y_categorical, inv_class_map\n",
    "\n",
    "def prepare_dataset(x , y , classes, input_shape):\n",
    "    x_scaled, input_shape = prepare_dataset_input(x, input_shape)\n",
    "    y_categorical, inv_class_map = prepare_dataset_output(y, classes)\n",
    "    return x_scaled , y_categorical, inv_class_map, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_by_class(model, x, y, verbose = 1):\n",
    "    def separate_by_class(x, y):\n",
    "        n_classes = y.shape[1]\n",
    "        x_classified = [[] for _ in range(n_classes)]\n",
    "        y_classified = [[] for _ in range(n_classes)]\n",
    "        \n",
    "        for i,img in enumerate(y):\n",
    "            index = np.where(img==1)[0][0]\n",
    "            x_classified[index].append(x[i])\n",
    "            y_classified[index].append(y[i])\n",
    "\n",
    "        for i in range(n_classes):\n",
    "            x_classified[i] = np.array(x_classified[i])\n",
    "            y_classified[i] = np.array(y_classified[i])\n",
    "            \n",
    "        return np.array(x_classified,dtype=object), np.array(y_classified,dtype=object)\n",
    "\n",
    "    x_by_class, y_by_class = separate_by_class(x,y)\n",
    "    \n",
    "    score_by_class = []\n",
    "    for i,(x,y) in enumerate(zip(x_by_class,y_by_class)):\n",
    "        score = model.evaluate(x, y, verbose = verbose)\n",
    "        score_by_class.append(score)\n",
    "\n",
    "    return score_by_class\n",
    "    \n",
    "def evaluate_model(model, x, y, inv_class_map, verbose = 1):\n",
    "    score = model.evaluate(x, y, verbose = verbose)\n",
    "    score_by_class = evaluate_model_by_class(model, x, y, verbose)\n",
    "\n",
    "    if verbose > 0:\n",
    "        print()\n",
    "        print(\"Global loss: %.4f\" % (score))\n",
    "        for i, s in enumerate(score_by_class):\n",
    "            print(\"Class %s loss: %.4f\" % (inv_class_map[i], s))\n",
    "\n",
    "    all_scores = {\n",
    "        'loss': score,\n",
    "        'loss_by_class': score_by_class\n",
    "    }\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_history(history,verbose):\n",
    "    if verbose > 0:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.plot(history['loss'], label=\"Loss\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(model, history, dir_path = 'results'):\n",
    "    results_directory = os.path.join(dir_path)\n",
    "\n",
    "    if not os.path.exists(results_directory):\n",
    "        os.makedirs(results_directory)\n",
    "    \n",
    "    now = datetime.now()\n",
    "    now_str = now.strftime(\"%Y-%m-%d-%H-%M-%S-%f\")\n",
    "\n",
    "    result_directory = os.path.join(results_directory,now_str)\n",
    "\n",
    "    if not os.path.exists(result_directory):\n",
    "        os.makedirs(result_directory)\n",
    "    else:\n",
    "        raise ValueError(\"File already exists.\")\n",
    "    \n",
    "    model_path = os.path.join(result_directory,'model')\n",
    "    model.save(model_path)\n",
    "\n",
    "    evaluation_path = os.path.join(result_directory,'evaluation')\n",
    "\n",
    "    evaluation = {\n",
    "            'epochs': history.params['epochs'],\n",
    "            'history': history.history\n",
    "    }\n",
    "\n",
    "    with open(evaluation_path, 'wb') as f:\n",
    "        pickle.dump(evaluation, f)\n",
    "    \n",
    "    print(\"Saved!\")\n",
    "    return now_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_result(foldername, dir_path = 'results'):\n",
    "    result_directory = os.path.join(dir_path,foldername)\n",
    "    if not os.path.exists(result_directory):\n",
    "        raise ValueError(\"Folder not found.\")\n",
    "    \n",
    "    model_path = os.path.join(result_directory,'model')\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    evaluation_path = os.path.join(result_directory,'evaluation')\n",
    "    evaluation = pickle.load(open(evaluation_path, \"rb\"))\n",
    "    \n",
    "    return model, evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_evaluation(foldername, name, all_scores, dir_path = 'results'):\n",
    "    result_directory = os.path.join(dir_path,foldername)\n",
    "    if not os.path.exists(result_directory):\n",
    "        raise ValueError(\"Folder not found.\")\n",
    "    \n",
    "    score_path = os.path.join(result_directory, name + '_score.json')\n",
    "    with open(score_path, 'w') as f:\n",
    "        json.dump(all_scores, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(classes, y):\n",
    "    class_weight = compute_class_weight('balanced', classes,  y)\n",
    "    return dict(zip(range(len(classes)),class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cnn(input_shape, classes, class_weight, verbose = 1):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu', input_shape=input_shape))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same', activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3), strides=(1,1),  padding='same', activation='relu'))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(len(classes), activation='softmax'))\n",
    "\n",
    "    if verbose > 0:\n",
    "        model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "\n",
    "    history = model.fit(x_train_prepared, y_train_prepared,\n",
    "                    batch_size=128,\n",
    "                    epochs=100, class_weight = class_weight, verbose=verbose)\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#foldername = 'simplecnn+classweight'\n",
    "#model, evaluation = load_result(foldername)\n",
    "#history = evaluation['history']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "dir_path = '../Alzheimer_s Dataset/train'\n",
    "verbose_loading = 0\n",
    "verbose_training = 1\n",
    "verbose_evaluating = 1\n",
    "dataset_percentage = 1\n",
    "validation_percentage = 0.2\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and preparing training dataset\n",
    "classes, input_shape, class_dist = analyse_dataset(dir_path, verbose_loading, seed)\n",
    "x, y = load_dataset(dir_path, dataset_percentage , verbose_loading)\n",
    "x_train, x_val, y_train, y_val = split_dataset(x, y, validation_percentage, verbose_loading, seed)\n",
    "x_train_prepared , y_train_prepared, inv_class_map, input_shape = prepare_dataset(x_train , y_train , classes, input_shape)\n",
    "x_val_prepared , y_val_prepared, _, _ = prepare_dataset(x_val , y_val , classes, input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=['MildDemented', 'ModerateDemented', 'NonDemented', 'VeryMildDemented'], y=['NonDemented' 'VeryMildDemented' 'VeryMildDemented' ... 'NonDemented'\n",
      " 'VeryMildDemented' 'NonDemented'] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "class_weight = get_class_weight(classes, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 208, 176, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 104, 88, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 104, 88, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 52, 44, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 52, 44, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 26, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 26, 22, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 13, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 13, 11, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 6, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 5, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 7684      \n",
      "=================================================================\n",
      "Total params: 192,964\n",
      "Trainable params: 192,964\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "32/32 [==============================] - 103s 3s/step - loss: 1.3893\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 103s 3s/step - loss: 1.3865\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 105s 3s/step - loss: 1.3862\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 104s 3s/step - loss: 1.3821\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 106s 3s/step - loss: 1.3106\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 101s 3s/step - loss: 1.0023\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 100s 3s/step - loss: 0.7509\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 101s 3s/step - loss: 0.5983\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 101s 3s/step - loss: 0.5197\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 0.4308\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 0.3440\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 0.2418\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.2047\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 101s 3s/step - loss: 0.1337\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 103s 3s/step - loss: 0.0811\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 0.0508\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 103s 3s/step - loss: 0.0233\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 102s 3s/step - loss: 0.0131\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 101s 3s/step - loss: 0.0900\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 101s 3s/step - loss: 0.1008\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 0.0264\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 0.0094\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 0.0027\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 9.6391e-04\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 5.8646e-04\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 99s 3s/step - loss: 4.5884e-04\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 3.8466e-04\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 3.3500e-04\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 2.9274e-04\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 2.5936e-04\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 2.3465e-04\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 2.1073e-04\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.9125e-04\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.7416e-04\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.6105e-04\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.4738e-04\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 1.3671e-04\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.2855e-04\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 1.1839e-04\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 1.0995e-04\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.0342e-04\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 9.6918e-05\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 9.1095e-05\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 8.5741e-05\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 8.1088e-05\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 7.6711e-05\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 7.2852e-05\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 6.8811e-05\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 6.5341e-05\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 6.2269e-05\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 5.9461e-05\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 5.6585e-05\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 5.3872e-05\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 5.1384e-05\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 4.9094e-05\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 4.6878e-05\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 4.4963e-05\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 4.3350e-05\n",
      "Epoch 59/100\n",
      "32/32 [==============================] - 106s 3s/step - loss: 4.1390e-05\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 3.9672e-05\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 116s 4s/step - loss: 3.8209e-05\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 3.6817e-05\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 103s 3s/step - loss: 3.5704e-05\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 102s 3s/step - loss: 3.3878e-05\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 103s 3s/step - loss: 3.2606e-05\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 3.1392e-05\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 105s 3s/step - loss: 3.0175e-05\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 108s 3s/step - loss: 2.9171e-05\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 2.8077e-05\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 2.6968e-05\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 2.6074e-05\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 2.5150e-05\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 111s 3s/step - loss: 2.4251e-05\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 2.3377e-05\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 106s 3s/step - loss: 2.2609e-05\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 116s 4s/step - loss: 2.1868e-05\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 2.1129e-05\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 109s 3s/step - loss: 2.0422e-05\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 108s 3s/step - loss: 1.9766e-05\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 110s 3s/step - loss: 1.9112e-05\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 116s 4s/step - loss: 1.8480e-05\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 105s 3s/step - loss: 1.7920e-05\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 102s 3s/step - loss: 1.7329e-05\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.6821e-05\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.6235e-05\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.5757e-05\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.5238e-05\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.4821e-05\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.4304e-05\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.3858e-05\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.3428e-05\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.3035e-05\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.2604e-05\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.2258e-05\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.1871e-05\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.1509e-05\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.1166e-05\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.0826e-05\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.0515e-05\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 98s 3s/step - loss: 1.0235e-05\n",
      "INFO:tensorflow:Assets written to: results\\2021-11-06-21-29-04-765819\\model\\assets\n",
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "# Executing\n",
    "model, history = run_cnn(input_shape, classes, class_weight, verbose_training)\n",
    "foldername = save_result(model, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training\n",
      "128/128 [==============================] - 24s 183ms/step - loss: 1.6432e-05\n",
      "18/18 [==============================] - 3s 171ms/step - loss: 2.4700e-06\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 7.2850e-08\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 1.9595e-05\n",
      "46/46 [==============================] - 8s 175ms/step - loss: 1.7721e-05\n",
      "\n",
      "Global loss: 0.0000\n",
      "Class MildDemented loss: 0.0000\n",
      "Class ModerateDemented loss: 0.0000\n",
      "Class NonDemented loss: 0.0000\n",
      "Class VeryMildDemented loss: 0.0000\n",
      "\n",
      "Validation\n",
      "33/33 [==============================] - 6s 175ms/step - loss: 0.0788\n",
      "5/5 [==============================] - 1s 191ms/step - loss: 0.3806\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.0390\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.0272\n",
      "11/11 [==============================] - 2s 178ms/step - loss: 0.0171\n",
      "\n",
      "Global loss: 0.0788\n",
      "Class MildDemented loss: 0.3806\n",
      "Class ModerateDemented loss: 0.0390\n",
      "Class NonDemented loss: 0.0272\n",
      "Class VeryMildDemented loss: 0.0171\n"
     ]
    }
   ],
   "source": [
    "# Evaluating CNN\n",
    "plot_loss_history(history.history,verbose_evaluating)\n",
    "print(\"\\nTraining\")\n",
    "train_score = evaluate_model(model, x_train_prepared, y_train_prepared, inv_class_map, verbose_evaluating)\n",
    "print(\"\\nValidation\")\n",
    "val_score = evaluate_model(model, x_val_prepared, y_val_prepared, inv_class_map, verbose_evaluating)\n",
    "save_evaluation(foldername,'training', train_score)\n",
    "save_evaluation(foldername,'validation', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
