{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "import os\n",
    "import random\n",
    "from matplotlib import image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import json\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from prettytable import PrettyTable \n",
    "from contextlib import redirect_stdout\n",
    "from sklearn.metrics import auc\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_analysis_histogram(dir_path):\n",
    "    \"\"\" Analisa o conjunto de dados\n",
    "\n",
    "    Retorna o tamanho da entrada e a distribuição das classes \n",
    "\n",
    "    Args:\n",
    "        dir_path: Caminho do conjunto de dados\n",
    "        \n",
    "    Returns:\n",
    "        Distribuição das classes\n",
    "    \"\"\"\n",
    "    \n",
    "    class_dist = []\n",
    "    for c in CLASSES:\n",
    "        class_path = os.path.join(dir_path, c)\n",
    "        class_dist.append(len(os.listdir(class_path)))\n",
    "\n",
    "    # Apresenta um histograma da distribuição das classes\n",
    "    if VERBOSE['ANALYSIS']:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(\"Distribuição das classes\")\n",
    "        plt.barh(CLASSES, class_dist)\n",
    "        for index, value in enumerate(class_dist):\n",
    "            plt.text(value, index, str(value))\n",
    "        plt.show()\n",
    "    return class_dist\n",
    "\n",
    "\n",
    "def data_analysis_image_size(dir_path):\n",
    "    \"\"\" Analisa o tamanho da entrada\n",
    "\n",
    "    Retorna o tamanho da entrada\n",
    "\n",
    "    Args:\n",
    "        dir_path: Caminho do conjunto de dados\n",
    "\n",
    "    Returns:\n",
    "        Dimensões da entrada\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(SEED)\n",
    "    random_class_path = os.path.join(dir_path, random.choice(CLASSES))\n",
    "    random_img_name = random.choice(os.listdir(random_class_path))\n",
    "    random_img_path = os.path.join(random_class_path, random_img_name)\n",
    "    img = image.imread(random_img_path)\n",
    "\n",
    "    # Apresenta aleatoriamente um exemplo do conjunto de dados e suas dimensões\n",
    "    # Espera-se que todo o conjunto de dados possua a mesma dimensão\n",
    "    if VERBOSE['ANALYSIS']:\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        plt.title(\"%s - Altura: %d px x Largura: %d px\" %\n",
    "                  (random_img_path, img.shape[0], img.shape[1]))\n",
    "        plt.imshow(img)\n",
    "\n",
    "    return (img.shape[0], img.shape[1], 1)\n",
    "\n",
    "\n",
    "def analyse_dataset(dir_path):\n",
    "    \"\"\" Analisa o conjunto de dados\n",
    "\n",
    "    Retorna o tamanho da entrada e a distribuição das classes.\n",
    "\n",
    "    Args:\n",
    "        dir_path: Caminho do conjunto de dados\n",
    "\n",
    "    Returns:\n",
    "        Dimensões da entrada,\n",
    "        Distribuição das classes\n",
    "    \"\"\"\n",
    "\n",
    "    class_dist = data_analysis_histogram(dir_path)\n",
    "    input_shape = data_analysis_image_size(dir_path)\n",
    "    return input_shape, class_dist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dir_path):\n",
    "    \"\"\" Carrega o conjunto de dados\n",
    "\n",
    "    Carrega e retorna as entradas e saídas do conjunto de dados.\n",
    "\n",
    "    Args:\n",
    "        dir_path: Caminho do conjunto de dados\n",
    "        \n",
    "    Returns:\n",
    "        Entrada do conjunto de dados,\n",
    "        Saída do conjunto de dados\n",
    "    \"\"\"\n",
    "\n",
    "    img_array = []\n",
    "    class_array = []\n",
    "    for c in CLASSES:\n",
    "        class_path = os.path.join(dir_path, c)\n",
    "        imgs_name = os.listdir(class_path)\n",
    "\n",
    "        # Aleatoriamente carregar a parcela do conjunto de dados definida por DATASET_PERCENTAGE\n",
    "        if DATASET_PERCENTAGE < 1:\n",
    "            imgs_name = random.sample(imgs_name, k=int(\n",
    "                len(imgs_name)*DATASET_PERCENTAGE))\n",
    "\n",
    "        for i in imgs_name:\n",
    "            img_array.append(image.imread(os.path.join(class_path, i)))\n",
    "            class_array.append(c)\n",
    "    if VERBOSE['LOADING']:\n",
    "        print(\"Loaded %d images\" % len(img_array))\n",
    "\n",
    "    return np.array(img_array), np.array(class_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y):\n",
    "    \"\"\" Divide o conjunto de dados em treinamento e validação\n",
    "\n",
    "    Divide a entrada e a saída em um conjunto de treinamento e de validação\n",
    "\n",
    "    Args:\n",
    "        x: entrada\n",
    "        y: saída\n",
    "        \n",
    "    Returns:\n",
    "        Entrada do conjunto de treinamento,\n",
    "        Entrada do conjunto de validação,\n",
    "        Saída do conjunto de treinamento,\n",
    "        Saída do conjunto de validação\n",
    "    \"\"\"\n",
    "    \n",
    "    if VALIDATION_PERCENTAGE <= 0:\n",
    "        return x, None, y, None\n",
    "\n",
    "    # Porcetagem da divisão dada por VALIDATION_PERCENTAGE\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x,  y, test_size=VALIDATION_PERCENTAGE, random_state=SEED)\n",
    "    if VERBOSE['SPLITTING']:\n",
    "        print(\"Train size: %d\\nValidation size: %d\" % (len(x_train), len(x_val)))\n",
    "    return x_train, x_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_channel_position(x, input_shape):\n",
    "    \"\"\" Reordenada as dimensões da entrada\n",
    "    \n",
    "    Reordenada a dimensão 'canal' conforme o formato esperado pelo classificador, podendo ser a primeira ou a última dimensão da matriz.\n",
    "    Portanto, uma entrada do tipo (linha, coluna, canal) pode ser reordenada para (canal, linha, coluna) caso o formato exija que o canal venha antes.\n",
    "    Args:\n",
    "        x: entrada\n",
    "        input_shape: dimensões da entrada\n",
    "        \n",
    "    Returns:\n",
    "        Entrada preparada para o classificador\n",
    "        Dimensões da entrada preparada para o classificador\n",
    "    \"\"\"\n",
    "\n",
    "    img_lin,img_col,n_channels = input_shape\n",
    "    if keras.backend.image_data_format() == 'channels_first':\n",
    "        x = x.reshape(x.shape[0], n_channels, img_lin, img_col)\n",
    "        input_shape = (n_channels, img_lin, img_col)\n",
    "    else:\n",
    "        x = x.reshape(x.shape[0], img_lin, img_col, n_channels)\n",
    "        input_shape = (img_lin, img_col, n_channels)\n",
    "    return x, input_shape\n",
    "\n",
    "def prepare_dataset_input(x, input_shape):\n",
    "    \"\"\" Prepara a entrada para o classificador\n",
    "    \n",
    "    A entrada é normalizada e suas dimensões reordenadas.\n",
    "\n",
    "    Args:\n",
    "        x: entrada\n",
    "        input_shape: dimensões da entrada\n",
    "        \n",
    "    Returns:\n",
    "        Entrada preparada para o classificador,\n",
    "        Dimensões da entrada preparada para o classificador\n",
    "    \"\"\"\n",
    "\n",
    "    x_scaled = x.astype('float32') / 255.0\n",
    "    return prepare_dataset_channel_position(x_scaled, input_shape)\n",
    "\n",
    "def prepare_dataset_output(y):\n",
    "    \"\"\" Prepara a saída conjunto de dados para o classificador\n",
    "    \n",
    "    A saída é transformada em um vetor one-hot encoding.\n",
    "\n",
    "    Args:\n",
    "        y: saída\n",
    "        \n",
    "    Returns:\n",
    "        Saída transformada\n",
    "    \"\"\"\n",
    "\n",
    "    class_map = {x: i for i,x in enumerate(CLASSES)}\n",
    "    y_code = [class_map[word] for word in y]\n",
    "    y_categorical = keras.utils.to_categorical(y_code, len(CLASSES))\n",
    "    return y_categorical\n",
    "\n",
    "def prepare_dataset(x , y, input_shape):\n",
    "    \"\"\" Prepara o conjunto de dados para o classificador\n",
    "    \n",
    "    Transforma a entrada e saída para alimentar o classificador.\n",
    "    A entrada é normalizada e suas dimensões reordenadas.\n",
    "    A saída é transformada em um vetor one-hot encoding.\n",
    "\n",
    "    Args:\n",
    "        x: entrada\n",
    "        y: saída\n",
    "        input_shape: dimensões da entrada\n",
    "        \n",
    "    Returns:\n",
    "        Entrada preparada para o classificador,\n",
    "        Saida preparada para o classificador,\n",
    "        Dimensões da entrada preparada para o classificador\n",
    "    \"\"\"\n",
    "\n",
    "    if x is None:\n",
    "        return None, None, None\n",
    "    x_scaled, input_shape = prepare_dataset_input(x, input_shape)\n",
    "    y_categorical = prepare_dataset_output(y)\n",
    "    return x_scaled , y_categorical, input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, training_param, history, elapsed_minutes):\n",
    "    \"\"\" Salva o modelo do classificador\n",
    "    \n",
    "    Salva o modelo, o resultados da execução do treinamento e o tempo de execução.\n",
    "\n",
    "    Args:\n",
    "        model: modelo do classificador\n",
    "        training_param: função que retorna parâmetros de treinamento\n",
    "        history: histórico do treinamento (saída do treinamento do classificador)\n",
    "        elapsed_minutes: tempo de execução do treinamento\n",
    "        \n",
    "    Returns:\n",
    "        Não há\n",
    "    \"\"\"\n",
    "\n",
    "    result_directory = os.path.join(RESULT_PATH)\n",
    "\n",
    "    # Cria diretório, caso não exista\n",
    "    if not os.path.exists(result_directory):\n",
    "        os.makedirs(result_directory)\n",
    "\n",
    "    result_directory = os.path.join(result_directory,model.name)\n",
    "\n",
    "    # Não permite a sobreescrita dos resultados\n",
    "    if not os.path.exists(result_directory):\n",
    "        os.makedirs(result_directory)\n",
    "    else:\n",
    "        raise ValueError(\"File already exists.\")\n",
    "    \n",
    "    model_path = os.path.join(result_directory,'model')\n",
    "    # Salva o modelo na pasta \"model\"\n",
    "    model.save(model_path)\n",
    "\n",
    "    execution_path = os.path.join(result_directory,'execution')\n",
    "\n",
    "    # Salva os resultados da execução no arquivo \"execution\"\n",
    "    optimizer, batch_size, epochs = training_param()\n",
    "\n",
    "    execution = {\n",
    "            'optimizer' : {'name': optimizer._name, 'hyper': optimizer._hyper},\n",
    "            'batch_size': batch_size,\n",
    "            'epochs': history.params['epochs'],\n",
    "            'history': history.history, # Contém resultados das métricas conforme a progressão do treinamento\n",
    "            'elapsed_minutes': elapsed_minutes\n",
    "    }\n",
    "\n",
    "    with open(execution_path, 'wb') as f:\n",
    "        pickle.dump(execution, f)\n",
    "    \n",
    "    # Salva o modelo no arquivo \"model_summary_txt\" em um formato de leitura mais fácil.\n",
    "    # Neste arquivo também é armazenado o tempo de execução do treinamento.\n",
    "    pretty_model_path = os.path.join(result_directory, 'model_summary.txt')\n",
    "\n",
    "    with open(pretty_model_path,'w') as f:\n",
    "        f.write('Elapsed time: '+str(elapsed_minutes)+' min\\n')\n",
    "        with redirect_stdout(f):\n",
    "            model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    \"\"\" Carrega o modelo do classificador\n",
    "    \n",
    "    Carrega o modelo do classificador armazenado no caminho dado.\n",
    "\n",
    "    Args:\n",
    "        model_name: nome do diretório que contém o modelo a ser carregado\n",
    "        \n",
    "    Returns:\n",
    "        Modelo do classificador, histórico da execução do treinamento\n",
    "    \"\"\"\n",
    "    \n",
    "    result_directory = os.path.join(RESULT_PATH, model_name)\n",
    "    if not os.path.exists(result_directory):\n",
    "        raise ValueError(\"Folder not found.\")\n",
    "    \n",
    "    model_path = os.path.join(result_directory,'model')\n",
    "    model = keras.models.load_model(model_path)\n",
    "\n",
    "    execution_path = os.path.join(result_directory,'execution')\n",
    "    execution = pickle.load(open(execution_path, \"rb\"))\n",
    "    \n",
    "    return model, execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_evaluation(model_name, evalution_name, all_scores, table):\n",
    "    \"\"\" Salva o resultado de uma avaliação do classificador\n",
    "    \n",
    "    Salva o resultado de uma avaliação do classificador, tanto em um formato JSON como em uma tabela para facilitar a leitura.\n",
    "\n",
    "    Args:\n",
    "        model_name: nome do diretório do modelo em que a avaliação será salva\n",
    "        evalution_name: nome da avaliação\n",
    "        all_scores: resultado da avaliação\n",
    "        table: tabela do resultado da avaliação\n",
    "        \n",
    "    Returns:\n",
    "        Não há\n",
    "    \"\"\"\n",
    "    \n",
    "    result_directory = os.path.join(RESULT_PATH,model_name)\n",
    "    if not os.path.exists(result_directory):\n",
    "        raise ValueError(\"Folder not found.\")\n",
    "    \n",
    "    # O resultado é salvo em um arquivo com o nome da avaliação e o sufixo \"_score\" no formato .json.\n",
    "    score_path = os.path.join(result_directory, evalution_name + '_score.json')\n",
    "    with open(score_path, 'w') as f:\n",
    "        json.dump(all_scores, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # A tabela é salva em um arquivo com o nome da avaliação e o sufixo \"_score_summary\" no formato .txt.\n",
    "    pretty_score_path = os.path.join(result_directory, evalution_name + '_score_summary.txt')\n",
    "\n",
    "    with open(pretty_score_path,'w') as f:\n",
    "        f.write(model_name+'\\n')\n",
    "        f.write(table.get_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_evaluation_roc(evaluation_name, model, x, y):\n",
    "    \"\"\" Desenha a curva ROC\n",
    "    \n",
    "    Desenha a curva ROC do modelo classificador com base na entrada e saída.\n",
    "\n",
    "    Args:\n",
    "        evalution_name: nome da avaliação\n",
    "        model: modelo do classificador\n",
    "        x: entrada\n",
    "        y: saída\n",
    "        \n",
    "    Returns:\n",
    "        Falso positivo,\n",
    "        Verdadeiro positivo,\n",
    "        Área sob a curva ROC\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = model.predict(x)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # Calcula a curva ROC para cada classe, baseado na predição do modelo e a saída real\n",
    "    for i in range(len(CLASSES)):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y[:, i], y_pred[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i in range(len(CLASSES)):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            label=\"ROC curve of {0} (AUC = {1:0.2f})\".format(CLASSES[i], roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Salva a imagem com o nome da avaliação e o com o sufixo \"_roc_curve\"\n",
    "    result_directory = os.path.join(RESULT_PATH, model.name)\n",
    "    image_path = os.path.join(result_directory,evaluation_name+'_roc_curve.png')\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "    # Exibe a curva ROC para cada classe\n",
    "    if VERBOSE['EVALUATION']:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "    return fpr, tpr, roc_auc\n",
    "    \n",
    "def evaluate_model_by_class(model, x, y):\n",
    "    \"\"\" Avalia o modelo por classes\n",
    "    \n",
    "    Faz a avaliação do modelo para cada classe do problema.\n",
    "\n",
    "    Args:\n",
    "        model: modelo do classificador\n",
    "        x: entrada\n",
    "        y: saída\n",
    "        \n",
    "    Returns:\n",
    "        Métrica por classe\n",
    "    \"\"\"\n",
    "    \n",
    "    def separate_by_class(x, y):\n",
    "        \"\"\" Separa a entrada e saída por classe\n",
    "    \n",
    "        Função interna que separa a entrada e saída por classe\n",
    "\n",
    "        Args:\n",
    "            x: entrada\n",
    "            y: saída\n",
    "            \n",
    "        Returns:\n",
    "            Entrada para cada classe,\n",
    "            Saída para cada classe\n",
    "        \"\"\"\n",
    "\n",
    "        n_classes = y.shape[1]\n",
    "        x_classified = [[] for _ in range(n_classes)]\n",
    "        y_classified = [[] for _ in range(n_classes)]\n",
    "        \n",
    "        # Separa as classes\n",
    "        for i,img in enumerate(y):\n",
    "            index = np.where(img==1)[0][0]\n",
    "            x_classified[index].append(x[i])\n",
    "            y_classified[index].append(y[i])\n",
    "\n",
    "        # Converte a entrada e saída para um array numpy\n",
    "        for i in range(n_classes):\n",
    "            x_classified[i] = np.array(x_classified[i])\n",
    "            y_classified[i] = np.array(y_classified[i])\n",
    "            \n",
    "        return np.array(x_classified,dtype=object), np.array(y_classified,dtype=object)\n",
    "\n",
    "    x_by_class, y_by_class = separate_by_class(x,y)\n",
    "    \n",
    "    score_by_class = []\n",
    "\n",
    "    # Avalia o modelo para cada classe\n",
    "    for x,y in zip(x_by_class,y_by_class):\n",
    "        score = model.evaluate(x, y, verbose = 1 if VERBOSE['EVALUATION'] else 0)\n",
    "        score_by_class.append(score)\n",
    "\n",
    "    return score_by_class\n",
    "\n",
    "def evaluate_model_confusion_matrix(evaluation_name, model, x, y):\n",
    "    \"\"\" Calcula a matriz de confusão\n",
    "    \n",
    "    Faz o cálculo da matriz de confusão do modelo de classificação.\n",
    "\n",
    "    Args:\n",
    "        evaluation_name: nome da avaliação\n",
    "        model: modelo do classificador\n",
    "        x: entrada\n",
    "        y: saída\n",
    "        \n",
    "    Returns:\n",
    "        Matriz de confusão\n",
    "    \"\"\"\n",
    "\n",
    "    def undoOneHotEncoding(y):\n",
    "        \"\"\" Desfaz a matriz one-hot encoding\n",
    "    \n",
    "        Transforma a matriz one-hot encoding para sua forma original, com o nome das classes.\n",
    "\n",
    "        Args:\n",
    "            y: saída\n",
    "            \n",
    "        Returns:\n",
    "            Saída transformada\n",
    "        \"\"\"\n",
    "\n",
    "        return [CLASSES[i] for i in np.argmax(y, axis = 1)]\n",
    "    \n",
    "    y_pred = model.predict(x)\n",
    "    y_pred_int = undoOneHotEncoding(y_pred)\n",
    "    y_int = undoOneHotEncoding(y)\n",
    "\n",
    "    # Cria a matriz de confusão baseado na previsão do modelo de classificação e o resultado real\n",
    "    cm = confusion_matrix(y_int, y_pred_int)\n",
    "\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                        index = [CLASSES[i] for i in range(len(CLASSES))], \n",
    "                        columns = [CLASSES[i] for i in range(len(CLASSES))])\n",
    "    plt.figure(figsize=(16,16))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    \n",
    "    # Salva a imagem com o nome da avaliação e o com o sufixo \"_confusion_matrix\"\n",
    "    results_directory = os.path.join(RESULT_PATH, model.name)\n",
    "    image_path = os.path.join(results_directory,evaluation_name+'_confusion_matrix.png')\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "    # Exibe a matriz de confusão\n",
    "    if VERBOSE['EVALUATION']:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    return cm\n",
    "\n",
    "def evaluate_model(evaluation_name, model, x, y):\n",
    "    \"\"\" Avalia o modelo\n",
    "    \n",
    "    Faz a análise do modelo, fazendo a avalição por classe, gerando a matriz de confusão e desenhando a curva ROC.\n",
    "\n",
    "    Args:\n",
    "        evaluation_name: nome da avaliação\n",
    "        model: modelo do classificador\n",
    "        x: entrada\n",
    "        y: saída\n",
    "        \n",
    "    Returns:\n",
    "        Resultado da avaliação\n",
    "    \"\"\"\n",
    "\n",
    "    if x is None:\n",
    "        return None\n",
    "\n",
    "    score = model.evaluate(x, y, verbose = 1 if VERBOSE['EVALUATION'] else 0)\n",
    "    score_by_class = evaluate_model_by_class(model, x, y)\n",
    "    cm = evaluate_model_confusion_matrix(evaluation_name, model,x, y)\n",
    "    _, _, roc_auc = plot_evaluation_roc(evaluation_name, model, x, y)\n",
    "    table = PrettyTable()\n",
    "    table.add_column(\"Metrics\", model.metrics_names)\n",
    "    table.add_column(\"Global\", np.round(score,4))\n",
    "\n",
    "    # Cria uma tabela dos resultados por classe\n",
    "    for i, s_class in enumerate(score_by_class):\n",
    "        table.add_column(CLASSES[i], np.round(s_class,4))\n",
    "\n",
    "    if VERBOSE['EVALUATION']:\n",
    "        print()\n",
    "        print(evaluation_name)\n",
    "        print(table)\n",
    "\n",
    "    all_scores = {\n",
    "        'model_name': model.name,\n",
    "        'name': evaluation_name,\n",
    "        'loss': score,\n",
    "        'loss_by_class': score_by_class,\n",
    "        'confusion': cm.tolist(),\n",
    "        'auc': list(roc_auc.values())\n",
    "    }\n",
    "\n",
    "    save_evaluation(model.name, evaluation_name, all_scores, table)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weight(y):\n",
    "    \"\"\" Retorna o peso para cada classe\n",
    "    \n",
    "    Retorna um de peso que cada classe para que se mitigue o problema de desbalanceamento do conjunto de dados.\n",
    "\n",
    "    Args:\n",
    "        y: saída\n",
    "        \n",
    "    Returns:\n",
    "        Peso para cada classe\n",
    "    \"\"\"\n",
    "\n",
    "    class_weight = compute_class_weight(class_weight ='balanced', classes = CLASSES, y = y)\n",
    "    return dict(zip(range(len(CLASSES)),class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics():\n",
    "    \"\"\" Retorna as métricas\n",
    "    \n",
    "    Retorna as métricas utilizadas para o problema.\n",
    "\n",
    "    Args:\n",
    "        Não há\n",
    "        \n",
    "    Returns:\n",
    "        Array com as métricas\n",
    "    \"\"\"\n",
    "\n",
    "    return [\n",
    "        keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "        keras.metrics.AUC(name='AUC'),\n",
    "        keras.metrics.AUC(name='PRC', curve='PR'), # precision-recall curve\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_execution_history(history, model):\n",
    "    \"\"\" Desenha o histórico do treinamento\n",
    "    \n",
    "    Desenha uma curva para cada métrica, incluindo a função de perda, pelas épocas.\n",
    "\n",
    "    Args:\n",
    "        history: histórico das métricas\n",
    "        model: modelo de classificação\n",
    "        \n",
    "    Returns:\n",
    "        Não há\n",
    "    \"\"\"\n",
    "\n",
    "    result_directory = os.path.join(RESULT_PATH, model.name)\n",
    "    image_path = os.path.join(result_directory,'execution.png')\n",
    "\n",
    "    # Se houver um conjunto dados de validação, o histórico de métricas possuirá o dobro de curvas\n",
    "    if VALIDATION_PERCENTAGE > 0:\n",
    "        nplots = len(history.values())/2\n",
    "    else:\n",
    "        nplots = len(history.values())\n",
    "    fig = plt.figure(figsize=(16, nplots*16))\n",
    "    # Apresentando os gráficos em somente 1 coluna\n",
    "    gs = fig.add_gridspec(nplots, 1)\n",
    "    axs = gs.subplots(sharex=False, sharey=False)\n",
    "\n",
    "    # Para cada métrica armazenada em history, desenhar sua curva conforme as épocas\n",
    "    for i,h in enumerate(history.values()):\n",
    "        if VALIDATION_PERCENTAGE > 0:\n",
    "            axs[i].plot(h, label = 'Training' if int(i/nplots)==0 else 'Validation')\n",
    "        else:\n",
    "            axs[i].plot(h,label = 'Training')\n",
    "\n",
    "    # Colocar uma legenda\n",
    "    for i,n in enumerate(model.metrics_names):\n",
    "        axs[i].set_xlabel('Epoch')\n",
    "        axs[i].set_ylabel(n)\n",
    "        axs[i].legend()\n",
    "      \n",
    "    plt.savefig(image_path)\n",
    "\n",
    "    # Exibe a curva de treinamento\n",
    "    if VERBOSE['EXECUTION']:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "def run_model(model, training_param, x_train, y_train, x_val, y_val, class_weight):\n",
    "    \"\"\" Desenha o histórico de execução do treinamento\n",
    "    \n",
    "    Desenha uma curva para cada métrica, incluindo a função de perda, pelas épocas.\n",
    "\n",
    "    Args:\n",
    "        model: modelo de classificação\n",
    "        training_param: função que retorna parâmetros de treinamento\n",
    "        x_train: entrada de treinamento\n",
    "        y_train: saída de treinamento\n",
    "        x_test: entrada de teste\n",
    "        y_test: saída de teste\n",
    "        class_weight: peso para cada classe\n",
    "        \n",
    "    Returns:\n",
    "        Modelo de classificação,\n",
    "        Histórico do treinamento\n",
    "    \"\"\"\n",
    "\n",
    "    optimizer, batch_size, epochs = training_param()\n",
    "\n",
    "    if VERBOSE['EXECUTION']:\n",
    "        model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=get_metrics())\n",
    "\n",
    "    if x_val is None:\n",
    "        xy_val = None\n",
    "    else:\n",
    "        xy_val = (x_val, y_val)\n",
    "\n",
    "    start_time = time.time()\n",
    "    # É dado o peso para o treinamento de cada classe a fim de mitigar o problema do desbalanceamento\n",
    "    history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data= xy_val,\n",
    "                    class_weight = class_weight,\n",
    "                    verbose=1 if VERBOSE['EXECUTION'] else 0)\n",
    "\n",
    "    elapsed_minute = round((time.time() - start_time)/60)\n",
    "\n",
    "    save_model(model,training_param, history, elapsed_minute)\n",
    "    plot_execution_history(history.history, model)\n",
    "      \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(models_func,training_param):\n",
    "    \"\"\" Treina e avalia um array de modelos\n",
    "    \n",
    "    Faz o carregamento do conjunto de dados, faz o treinamento e a avaliação de cada um dos modelos.\n",
    "\n",
    "    Args:\n",
    "        models_func: array de modelos de classificação\n",
    "        training_param: função que retorna parâmetros de treinamento\n",
    "        \n",
    "    Returns:\n",
    "        Não há\n",
    "    \"\"\"\n",
    "\n",
    "    if os.path.isdir(RESULT_PATH):\n",
    "        print(\"Folder already exists\")\n",
    "        return\n",
    "\n",
    "    input_shape, _ = analyse_dataset(TRAIN_DIR_PATH)\n",
    "    _, _ = analyse_dataset(TEST_DIR_PATH)\n",
    "    x_trainval, y_trainval = load_dataset(TRAIN_DIR_PATH)\n",
    "    x_test, y_test = load_dataset(TEST_DIR_PATH)\n",
    "    x_train, x_val, y_train, y_val = split_dataset(x_trainval, y_trainval)\n",
    "    x_train_prepared , y_train_prepared, _ = prepare_dataset(x_train , y_train, input_shape)\n",
    "    x_val_prepared , y_val_prepared, _ = prepare_dataset(x_val , y_val, input_shape)\n",
    "    x_test_prepared , y_test_prepared, _ = prepare_dataset(x_test , y_test, input_shape)    \n",
    "    for model_func in models_func:\n",
    "        model = model_func(input_shape,len(CLASSES))\n",
    "        print(\"Training:\", model.name)\n",
    "        model, history = run_model(model,training_param, x_train_prepared, y_train_prepared, x_val_prepared, y_val_prepared, get_class_weight(y_train))\n",
    "        history = history.history\n",
    "        evaluate_model('training',model, x_train_prepared, y_train_prepared)\n",
    "        evaluate_model('validation', model, x_val_prepared, y_val_prepared)\n",
    "        evaluate_model('test', model, x_test_prepared, y_test_prepared)\n",
    "        print(\"done\\n\")\n",
    "\n",
    "def reevaluate():\n",
    "    \"\"\" Reavalia os modelos treinados\n",
    "    \n",
    "    Faz a reavaliação dos modelos já treinados.\n",
    "\n",
    "    Args:\n",
    "        Não há\n",
    "        \n",
    "    Returns:\n",
    "        Não há\n",
    "    \"\"\"\n",
    "    \n",
    "    input_shape, _ = analyse_dataset()\n",
    "    x_trainval, y_trainval = load_dataset(TRAIN_DIR_PATH)\n",
    "    x_test, y_test = load_dataset(TEST_DIR_PATH)\n",
    "    x_train, x_val, y_train, y_val = split_dataset(x_trainval, y_trainval)\n",
    "    x_train_prepared , y_train_prepared, _ = prepare_dataset(x_train , y_train , input_shape)\n",
    "    x_val_prepared , y_val_prepared, _ = prepare_dataset(x_val , y_val, input_shape)\n",
    "    x_test_prepared , y_test_prepared, _ = prepare_dataset(x_test , y_test, input_shape)\n",
    "    for f in os.listdir(RESULT_PATH): \n",
    "        model, _ = load_model(f)\n",
    "        print(\"Reevaluating:\", model.name)\n",
    "        evaluate_model('training',model, x_train_prepared, y_train_prepared)\n",
    "        evaluate_model('validation', model, x_val_prepared, y_val_prepared)\n",
    "        evaluate_model('test', model, x_test_prepared, y_test_prepared)\n",
    "        print(\"done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_reshuffle():\n",
    "    \"\"\" Carrega, mistura e reparticiona os conjuntos de dados de treinamento e teste\n",
    "\n",
    "    Carrega e retorna as entradas e saídas do conjunto de dados de treinamento de teste, após serem carregados, embaralhados e reparticionados.\n",
    "\n",
    "    Args:\n",
    "        Não há\n",
    "        \n",
    "    Returns:\n",
    "        Entrada do conjunto de dados de treinamento,\n",
    "        Saída do conjunto de dados de treinamento,\n",
    "        Entrada do conjunto de dados de teste,\n",
    "        Saída do conjunto de dados de teste,\n",
    "    \"\"\"\n",
    "\n",
    "    img_array_train = []\n",
    "    class_array_train = []\n",
    "    img_array_test = []\n",
    "    class_array_test = []\n",
    "\n",
    "    for c in CLASSES:\n",
    "        class_path_train = os.path.join(TRAIN_DIR_PATH, c)\n",
    "        class_path_test = os.path.join(TEST_DIR_PATH, c)\n",
    "        \n",
    "        imgs_path = []\n",
    "        for img_name in os.listdir(class_path_train):\n",
    "            imgs_path.append(os.path.join(class_path_train, img_name))\n",
    "\n",
    "        for img_name in os.listdir(class_path_test):\n",
    "            imgs_path.append(os.path.join(class_path_test, img_name)) \n",
    "\n",
    "        random.shuffle(imgs_path)\n",
    "        \n",
    "        # Porcentagem original de treino e teste: 80% - 20%\n",
    "        test_size = int(len(imgs_path)*0.2)\n",
    "        train_size = len(imgs_path) - test_size\n",
    "            \n",
    "        for i in range(train_size):\n",
    "            img_array_train.append(image.imread(imgs_path[i]))\n",
    "            class_array_train.append(c)\n",
    "\n",
    "        for i in range(test_size):\n",
    "            img_array_test.append(image.imread(imgs_path[train_size+i]))\n",
    "            class_array_test.append(c)\n",
    "\n",
    "    if VERBOSE['LOADING']:\n",
    "        print(\"Loaded %d train images\" % len(img_array_train))\n",
    "        print(\"Loaded %d test images\" % len(img_array_test))\n",
    "\n",
    "    return np.array(img_array_train), np.array(class_array_train),np.array(img_array_test), np.array(class_array_test)\n",
    "\n",
    "def train_and_evaluate_reshuffled_dataset(models_func,training_param):\n",
    "    input_shape, _ = analyse_dataset(TRAIN_DIR_PATH)\n",
    "    _, _ = analyse_dataset(TEST_DIR_PATH)\n",
    "    x_trainval, y_trainval, x_test, y_test = load_dataset_reshuffle()\n",
    "\n",
    "    x_train, x_val, y_train, y_val = split_dataset(x_trainval, y_trainval)\n",
    "    x_train_prepared , y_train_prepared, _ = prepare_dataset(x_train , y_train , input_shape)\n",
    "    x_val_prepared , y_val_prepared, _ = prepare_dataset(x_val , y_val, input_shape)\n",
    "    x_test_prepared , y_test_prepared, _ = prepare_dataset(x_test , y_test, input_shape)\n",
    "    for model_func in models_func:\n",
    "        model = model_func(input_shape,len(CLASSES))\n",
    "        print(\"Training:\", model.name)\n",
    "        model, history = run_model(model,training_param, x_train_prepared, y_train_prepared, x_val_prepared, y_val_prepared, get_class_weight(y_train))\n",
    "        history = history.history\n",
    "        evaluate_model('training',model, x_train_prepared, y_train_prepared)\n",
    "        evaluate_model('validation', model, x_val_prepared, y_val_prepared)\n",
    "        evaluate_model('test', model, x_test_prepared, y_test_prepared)\n",
    "        print(\"done\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
