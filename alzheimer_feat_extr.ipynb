{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run alzheimer.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_feat_extr_resize_to_model(x, model_input_shape):\n",
    "    \"\"\" Redefine as dimensões da entrada para ser compatível ao modelo da extração de características. \n",
    "\n",
    "    Retorna o tamanho da entrada e a distribuição das classes \n",
    "\n",
    "    Args:\n",
    "        x: entrada\n",
    "        model_input_shape: dimensões esperadas pelo modelo de extração de características\n",
    "        \n",
    "    Returns:\n",
    "        Entrada redimensionada\n",
    "    \"\"\"\n",
    "\n",
    "    X = []\n",
    "    for i in range(0, x.shape[0]):\n",
    "        # A imagem na escala de cinza é replicada para os 3 canais de cor, pois os modelos de extração de características esperam imagens coloridas.\n",
    "        img = Image.fromarray(x[i], mode=\"RGB\")\n",
    "        X.append(np.array(img.resize(size=model_input_shape)))\n",
    "    return np.array(X)\n",
    "\n",
    "\n",
    "def prepare_dataset_feat_extr_input(x, input_shape, model_input_shape):\n",
    "    \"\"\" Prepara a entrada para a extração de características\n",
    "\n",
    "    Reordenadas as dimensões da entrada e ajusta o seu tamanho para ser compatível ao modelo da extração de características.\n",
    "\n",
    "    Args:\n",
    "        x: entrada\n",
    "        input_shape: dimensões da entrada\n",
    "        model_input_shape: dimensões esperadas pelo modelo de extração de características\n",
    "        \n",
    "    Returns:\n",
    "        Entrada preparada para a extração de características\n",
    "    \"\"\"\n",
    "\n",
    "    x_channel_formatted, _ = prepare_dataset_channel_position(\n",
    "        x.astype('float32'), input_shape)\n",
    "    return prepare_dataset_feat_extr_resize_to_model(x_channel_formatted, model_input_shape)\n",
    "\n",
    "\n",
    "def prepare_dataset_feat_extr(x, y, input_shape, model_input_shape):\n",
    "    \"\"\" Prepara o conjunto de dados para a extração de características\n",
    "\n",
    "    Reordenadas as dimensões da entrada e ajusta o seu tamanho para ser compatível ao modelo da extração de características.\n",
    "\n",
    "    Args:\n",
    "        x: entrada\n",
    "        y: saída\n",
    "        input_shape: dimensões da entrada\n",
    "        model_input_shape: dimensões esperadas pelo modelo de extração de características\n",
    "        \n",
    "    Returns:\n",
    "        Entrada preparada para a extração de características,\n",
    "        Saída preparada para a extração de características\n",
    "    \"\"\"\n",
    "\n",
    "    x_prepared = prepare_dataset_feat_extr_input(\n",
    "        x, input_shape, model_input_shape)\n",
    "        \n",
    "    # A saída é inalterada\n",
    "    return x_prepared, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_feature(model, x):\n",
    "    \"\"\" Transforma a entrada em um conjunto de características utilizando o modelo\n",
    "\n",
    "    Faz a previsão da entrada pelo modelo da extração de características. A saída gerada são as características extraídas.\n",
    "\n",
    "    Args:\n",
    "        model: modelo de extração de característica\n",
    "        x: entrada\n",
    "      \n",
    "    Returns:\n",
    "        Características extraídas do modelo\n",
    "    \"\"\"\n",
    "\n",
    "    prediction = np.array(model.predict(x))\n",
    "    return np.reshape(prediction, (prediction.shape[0], prediction.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(model_and_parameter):\n",
    "    \"\"\" Realiza a extração de características do modelo\n",
    "\n",
    "    Faz a leitura do conjunto de dados e extrai suas características.\n",
    "\n",
    "    Args:\n",
    "        model_and_parameter: variável que contém tanto o modelo como as dimensões da entrada esperada por ele\n",
    "      \n",
    "    Returns:\n",
    "        Entrada de treinamento extraída,\n",
    "        Saída de treinamento extraída,\n",
    "        Entrada de teste extraída,\n",
    "        Saída de teste extraída    \n",
    "    \"\"\"\n",
    "    \n",
    "    model, model_input_shape = model_and_parameter()\n",
    "\n",
    "    input_shape, _ = analyse_dataset(TRAIN_DIR_PATH)\n",
    "    _, _ = analyse_dataset(TEST_DIR_PATH)\n",
    "    x_trainval, y_trainval = load_dataset(TRAIN_DIR_PATH)\n",
    "    x_test, y_test = load_dataset(TEST_DIR_PATH)\n",
    "\n",
    "    x_train, _, y_train, _ = split_dataset(x_trainval, y_trainval)\n",
    "\n",
    "    x_train_prepared, y_train_prepared = prepare_dataset_feat_extr(\n",
    "        x_train, y_train, input_shape, model_input_shape)\n",
    "    x_test_prepared, y_test_prepared = prepare_dataset_feat_extr(\n",
    "        x_test, y_test, input_shape, model_input_shape)\n",
    "\n",
    "    x_train_extracted = extract_feature(model, x_train_prepared)\n",
    "    x_test_extracted = extract_feature(model, x_test_prepared)\n",
    "\n",
    "    return x_train_extracted, y_train_prepared, x_test_extracted, y_test_prepared\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_evaluate(model_and_parameter, classifier):\n",
    "    \"\"\" Faz a extração e classificação do conjunto de dados\n",
    "\n",
    "    Faz a extração de característica e a usa como entrada do classificador. O resultado produzido pelo classificador é o resultado final.\n",
    "\n",
    "    Args:\n",
    "        model_and_parameter: variável que contém tanto o modelo como as dimensões da entrada esperada por ele\n",
    "        classifier: classificador\n",
    "\n",
    "    Returns:\n",
    "        Acurácia \n",
    "    \"\"\"\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = feature_extraction(model_and_parameter)\n",
    "    acc , _ = classifier(x_train, y_train, x_test, y_test)\n",
    "    return acc,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_evaluation_feat_extract(evalution_name, all_scores, table):\n",
    "    \"\"\" Salva o resultado de uma avaliação do classificador\n",
    "    \n",
    "    Salva o resultado de uma avaliação do classificador, tanto em um formato JSON como em uma tabela para facilitar a leitura.\n",
    "\n",
    "    Args:\n",
    "        model_name: nome do diretório do modelo em que a avaliação será salva\n",
    "        evalution_name: nome da avaliação\n",
    "        all_scores: resultado da avaliação\n",
    "        table: tabela do resultado da avaliação\n",
    "        \n",
    "    Returns:\n",
    "        Não há\n",
    "    \"\"\"\n",
    "    \n",
    "    result_directory = RESULT_PATH\n",
    "    if not os.path.exists(result_directory):\n",
    "        raise ValueError(\"Folder not found.\")\n",
    "    \n",
    "    # O resultado é salvo em um arquivo com o nome da avaliação e o sufixo \"_score\" no formato .json.\n",
    "    score_path = os.path.join(result_directory, evalution_name + '_score.json')\n",
    "    with open(score_path, 'w') as f:\n",
    "        json.dump(all_scores, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    # A tabela é salva em um arquivo com o nome da avaliação e o sufixo \"_score_summary\" no formato .txt.\n",
    "    pretty_score_path = os.path.join(result_directory, evalution_name + '_score_summary.txt')\n",
    "\n",
    "    with open(pretty_score_path,'w') as f:\n",
    "        f.write(table.get_string())\n",
    "\n",
    "def plot_evaluation_roc_feat_extract(evaluation_name, classifier, x, y):\n",
    "\n",
    "    y_pred = classifier.predict(x)\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    # Calcula a curva ROC para cada classe, baseado na predição do modelo e a saída real\n",
    "    for i in range(len(CLASSES)):\n",
    "        fpr[i], tpr[i], _ = roc_curve((y==CLASSES[i])*1, (y_pred==CLASSES[i])*1)\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    plt.figure(figsize=(16, 16))\n",
    "    for i in range(len(CLASSES)):\n",
    "        plt.plot(\n",
    "            fpr[i],\n",
    "            tpr[i],\n",
    "            label=\"ROC curve of {0} (AUC = {1:0.2f})\".format(CLASSES[i], roc_auc[i]))\n",
    "    plt.plot([0, 1], [0, 1], \"k--\")\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Salva a imagem com o nome da avaliação e o com o sufixo \"_roc_curve\"\n",
    "    image_path = os.path.join(RESULT_PATH,evaluation_name+'_roc_curve.png')\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "    # Exibe a curva ROC para cada classe\n",
    "    if VERBOSE['EVALUATION']:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "        \n",
    "    return fpr, tpr, roc_auc\n",
    "def evaluate_model_by_class_feat_extract(classifier, x, y):\n",
    "    def separate_by_class(x, y):\n",
    "\n",
    "        n_classes = len(CLASSES)\n",
    "        x_classified = [[] for _ in range(n_classes)]\n",
    "        y_classified = [[] for _ in range(n_classes)]\n",
    "        \n",
    "        # Separa as classes\n",
    "        for i,img in enumerate(y):\n",
    "            index = np.where(np.array(CLASSES)==img)[0][0]\n",
    "            x_classified[index].append(x[i])\n",
    "            y_classified[index].append(img)\n",
    "\n",
    "        # Converte a entrada e saída para um array numpy\n",
    "        for i in range(n_classes):\n",
    "            x_classified[i] = np.array(x_classified[i])\n",
    "            y_classified[i] = np.array(y_classified[i])\n",
    "            \n",
    "        return np.array(x_classified,dtype=object), np.array(y_classified,dtype=object)\n",
    "\n",
    "    x_by_class, y_by_class = separate_by_class(x,y)\n",
    "\n",
    "    score_by_class = []\n",
    "\n",
    "    # Avalia o modelo para cada classe\n",
    "    for x_class, y_class in zip(x_by_class,y_by_class):\n",
    "        predicted = classifier.predict(x_class)\n",
    "\n",
    "        y_class.shape\n",
    "        score = accuracy_score(predicted,y_class)\n",
    "        score_by_class.append(score)\n",
    "\n",
    "    return score_by_class\n",
    "\n",
    "def evaluate_model_confusion_matrix_feat_extract(evaluation_name, classifier, x, y):\n",
    "    y_pred = classifier.predict(x)\n",
    "\n",
    "    # Cria a matriz de confusão baseado na previsão do modelo de classificação e o resultado real\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "\n",
    "    cm_df = pd.DataFrame(cm,\n",
    "                        index = [CLASSES[i] for i in range(len(CLASSES))], \n",
    "                        columns = [CLASSES[i] for i in range(len(CLASSES))])\n",
    "    plt.figure(figsize=(16,16))\n",
    "    sns.heatmap(cm_df, annot=True)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.xlabel('Predicted Values')\n",
    "    \n",
    "    # Salva a imagem com o nome da avaliação e o com o sufixo \"_confusion_matrix\"\n",
    "    image_path = os.path.join(RESULT_PATH,evaluation_name+'_confusion_matrix.png')\n",
    "    plt.savefig(image_path)\n",
    "\n",
    "    # Exibe a matriz de confusão\n",
    "    if VERBOSE['EVALUATION']:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()\n",
    "    return cm\n",
    "\n",
    "\n",
    "def evaluate_feat_extract(evaluation_name, classifier, x, y):\n",
    "    if x is None:\n",
    "        return None\n",
    "\n",
    "    predicted = classifier.predict(x)\n",
    "    score = accuracy_score(predicted,np.ravel(y, order='C'))\n",
    "    score_by_class = evaluate_model_by_class_feat_extract(classifier, x, y)\n",
    "    cm = evaluate_model_confusion_matrix_feat_extract(evaluation_name, classifier,x, y)\n",
    "    _, _, roc_auc = plot_evaluation_roc_feat_extract(evaluation_name, classifier, x, y)\n",
    "    table = PrettyTable()\n",
    "    table.add_column(\"Metrics\", [\"Accuracy\"])\n",
    "    table.add_column(\"Global\", [np.round(score,4)])\n",
    "\n",
    "\n",
    "    # Cria uma tabela dos resultados por classe\n",
    "    for i, s_class in enumerate(score_by_class):\n",
    "        table.add_column(CLASSES[i], [np.round(s_class,4)])\n",
    "    if VERBOSE['EVALUATION']:\n",
    "        print()\n",
    "        print(evaluation_name)\n",
    "        print(table)\n",
    "\n",
    "    all_scores = {\n",
    "        'name': evaluation_name,\n",
    "        'loss': score,\n",
    "        'loss_by_class': score_by_class,\n",
    "        'confusion': cm.tolist(),\n",
    "        'auc': list(roc_auc.values())\n",
    "    }\n",
    "\n",
    "    save_evaluation_feat_extract(evaluation_name, all_scores, table)\n",
    "\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_feat_extract(classifier,x,y):\n",
    "    classifier.fit(x,y)\n",
    "    return classifier\n",
    "\n",
    "def extract_and_evaluate2(model_and_parameter, classifier):\n",
    "    x_train, y_train, x_test, y_test = feature_extraction(model_and_parameter)\n",
    "    classifier_fit = classify_feat_extract(classifier(y_train),x_train,y_train)\n",
    "    evaluate_feat_extract('train', classifier_fit, x_train, y_train)\n",
    "    evaluate_feat_extract('test', classifier_fit, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
